Dump of assembler code for function count_pairs:
ex2b.c:
8	count_pairs(uint8_t *data, uint64_t size, uint8_t target) {
   0x00000000000019c0 <+0>:	f3 0f 1e fa	endbr64 

/usr/lib/gcc/x86_64-linux-gnu/11/include/avxintrin.h:
1342	  return _mm256_set_epi8 (__A, __A, __A, __A, __A, __A, __A, __A,
   0x00000000000019c4 <+4>:	48 89 f9	mov    %rdi,%rcx
   0x00000000000019c7 <+7>:	48 89 f7	mov    %rsi,%rdi
   0x00000000000019ca <+10>:	62 f2 7d 28 7a c2	vpbroadcastb %edx,%ymm0

ex2b.c:
12	  for (uint64_t i = 0; i < size * 2; i += 32) {
   0x00000000000019d0 <+16>:	48 01 ff	add    %rdi,%rdi
   0x00000000000019d3 <+19>:	0f 84 27 02 00 00	je     0x1c00 <count_pairs+576>

/usr/lib/gcc/x86_64-linux-gnu/11/include/avx2intrin.h:
233	  return (__m256i) ((__v32qi)__A == (__v32qi)__B);
   0x00000000000019d9 <+25>:	c5 fd 74 09	vpcmpeqb (%rcx),%ymm0,%ymm1

234	}
235	
236	extern __inline __m256i
237	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
238	_mm256_cmpeq_epi16 (__m256i __A, __m256i __B)
239	{
240	  return (__m256i) ((__v16hi)__A == (__v16hi)__B);
241	}
242	
243	extern __inline __m256i
244	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
245	_mm256_cmpeq_epi32 (__m256i __A, __m256i __B)
246	{
247	  return (__m256i) ((__v8si)__A == (__v8si)__B);
248	}
249	
250	extern __inline __m256i
251	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
252	_mm256_cmpeq_epi64 (__m256i __A, __m256i __B)
253	{
254	  return (__m256i) ((__v4di)__A == (__v4di)__B);
255	}
256	
257	extern __inline __m256i
258	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
259	_mm256_cmpgt_epi8 (__m256i __A, __m256i __B)
260	{
261	  return (__m256i) ((__v32qs)__A > (__v32qs)__B);
262	}
263	
264	extern __inline __m256i
265	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
266	_mm256_cmpgt_epi16 (__m256i __A, __m256i __B)
267	{
268	  return (__m256i) ((__v16hi)__A > (__v16hi)__B);
269	}
270	
271	extern __inline __m256i
272	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
273	_mm256_cmpgt_epi32 (__m256i __A, __m256i __B)
274	{
275	  return (__m256i) ((__v8si)__A > (__v8si)__B);
276	}
277	
278	extern __inline __m256i
279	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
280	_mm256_cmpgt_epi64 (__m256i __A, __m256i __B)
281	{
282	  return (__m256i) ((__v4di)__A > (__v4di)__B);
283	}
284	
285	extern __inline __m256i
286	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
287	_mm256_hadd_epi16 (__m256i __X, __m256i __Y)
288	{
289	  return (__m256i) __builtin_ia32_phaddw256 ((__v16hi)__X,
290						     (__v16hi)__Y);
291	}
292	
293	extern __inline __m256i
294	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
295	_mm256_hadd_epi32 (__m256i __X, __m256i __Y)
296	{
297	  return (__m256i) __builtin_ia32_phaddd256 ((__v8si)__X, (__v8si)__Y);
298	}
299	
300	extern __inline __m256i
301	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
302	_mm256_hadds_epi16 (__m256i __X, __m256i __Y)
303	{
304	  return (__m256i) __builtin_ia32_phaddsw256 ((__v16hi)__X,
305						      (__v16hi)__Y);
306	}
307	
308	extern __inline __m256i
309	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
310	_mm256_hsub_epi16 (__m256i __X, __m256i __Y)
311	{
312	  return (__m256i) __builtin_ia32_phsubw256 ((__v16hi)__X,
313						     (__v16hi)__Y);
314	}
315	
316	extern __inline __m256i
317	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
318	_mm256_hsub_epi32 (__m256i __X, __m256i __Y)
319	{
320	  return (__m256i) __builtin_ia32_phsubd256 ((__v8si)__X, (__v8si)__Y);
321	}
322	
323	extern __inline __m256i
324	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
325	_mm256_hsubs_epi16 (__m256i __X, __m256i __Y)
326	{
327	  return (__m256i) __builtin_ia32_phsubsw256 ((__v16hi)__X,
328						      (__v16hi)__Y);
329	}
330	
331	extern __inline __m256i
332	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
333	_mm256_maddubs_epi16 (__m256i __X, __m256i __Y)
334	{
335	  return (__m256i) __builtin_ia32_pmaddubsw256 ((__v32qi)__X,
336							(__v32qi)__Y);
337	}
338	
339	extern __inline __m256i
340	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
341	_mm256_madd_epi16 (__m256i __A, __m256i __B)
342	{
343	  return (__m256i)__builtin_ia32_pmaddwd256 ((__v16hi)__A,
344						     (__v16hi)__B);
345	}
346	
347	extern __inline __m256i
348	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
349	_mm256_max_epi8 (__m256i __A, __m256i __B)
350	{
351	  return (__m256i)__builtin_ia32_pmaxsb256 ((__v32qi)__A, (__v32qi)__B);
352	}
353	
354	extern __inline __m256i
355	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
356	_mm256_max_epi16 (__m256i __A, __m256i __B)
357	{
358	  return (__m256i)__builtin_ia32_pmaxsw256 ((__v16hi)__A, (__v16hi)__B);
359	}
360	
361	extern __inline __m256i
362	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
363	_mm256_max_epi32 (__m256i __A, __m256i __B)
364	{
365	  return (__m256i)__builtin_ia32_pmaxsd256 ((__v8si)__A, (__v8si)__B);
366	}
367	
368	extern __inline __m256i
369	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
370	_mm256_max_epu8 (__m256i __A, __m256i __B)
371	{
372	  return (__m256i)__builtin_ia32_pmaxub256 ((__v32qi)__A, (__v32qi)__B);
373	}
374	
375	extern __inline __m256i
376	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
377	_mm256_max_epu16 (__m256i __A, __m256i __B)
378	{
379	  return (__m256i)__builtin_ia32_pmaxuw256 ((__v16hi)__A, (__v16hi)__B);
380	}
381	
382	extern __inline __m256i
383	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
384	_mm256_max_epu32 (__m256i __A, __m256i __B)
385	{
386	  return (__m256i)__builtin_ia32_pmaxud256 ((__v8si)__A, (__v8si)__B);
387	}
388	
389	extern __inline __m256i
390	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
391	_mm256_min_epi8 (__m256i __A, __m256i __B)
392	{
393	  return (__m256i)__builtin_ia32_pminsb256 ((__v32qi)__A, (__v32qi)__B);
394	}
395	
396	extern __inline __m256i
397	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
398	_mm256_min_epi16 (__m256i __A, __m256i __B)
399	{
400	  return (__m256i)__builtin_ia32_pminsw256 ((__v16hi)__A, (__v16hi)__B);
401	}
402	
403	extern __inline __m256i
404	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
405	_mm256_min_epi32 (__m256i __A, __m256i __B)
406	{
407	  return (__m256i)__builtin_ia32_pminsd256 ((__v8si)__A, (__v8si)__B);
408	}
409	
410	extern __inline __m256i
411	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
412	_mm256_min_epu8 (__m256i __A, __m256i __B)
413	{
414	  return (__m256i)__builtin_ia32_pminub256 ((__v32qi)__A, (__v32qi)__B);
415	}
416	
417	extern __inline __m256i
418	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
419	_mm256_min_epu16 (__m256i __A, __m256i __B)
420	{
421	  return (__m256i)__builtin_ia32_pminuw256 ((__v16hi)__A, (__v16hi)__B);
422	}
423	
424	extern __inline __m256i
425	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
426	_mm256_min_epu32 (__m256i __A, __m256i __B)
427	{
428	  return (__m256i)__builtin_ia32_pminud256 ((__v8si)__A, (__v8si)__B);
429	}
430	
431	extern __inline int
432	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
433	_mm256_movemask_epi8 (__m256i __A)
434	{
435	  return __builtin_ia32_pmovmskb256 ((__v32qi)__A);
   0x00000000000019dd <+29>:	c5 fd d7 c1	vpmovmskb %ymm1,%eax

ex2b.c:
15	    total += __builtin_popcount(block & (block >> 1U));
   0x00000000000019e1 <+33>:	41 89 c0	mov    %eax,%r8d
   0x00000000000019e4 <+36>:	41 d1 e8	shr    %r8d
   0x00000000000019e7 <+39>:	41 21 c0	and    %eax,%r8d
   0x00000000000019ea <+42>:	f3 45 0f b8 c0	popcnt %r8d,%r8d

17	      total += last_bit & block;
18	    }
19	    last_bit = block >> 31U;
   0x00000000000019ef <+47>:	c1 e8 1f	shr    $0x1f,%eax

12	  for (uint64_t i = 0; i < size * 2; i += 32) {
   0x00000000000019f2 <+50>:	48 83 ff 20	cmp    $0x20,%rdi
   0x00000000000019f6 <+54>:	0f 86 fa 01 00 00	jbe    0x1bf6 <count_pairs+566>
   0x00000000000019fc <+60>:	c5 fd 74 51 20	vpcmpeqb 0x20(%rcx),%ymm0,%ymm2
   0x0000000000001a01 <+65>:	45 31 d2	xor    %r10d,%r10d
   0x0000000000001a04 <+68>:	4c 8d 4f df	lea    -0x21(%rdi),%r9
   0x0000000000001a08 <+72>:	c5 fd d7 d2	vpmovmskb %ymm2,%edx
   0x0000000000001a0c <+76>:	89 d6	mov    %edx,%esi
   0x0000000000001a0e <+78>:	d1 ee	shr    %esi
   0x0000000000001a10 <+80>:	21 d6	and    %edx,%esi
   0x0000000000001a12 <+82>:	f3 44 0f b8 d6	popcnt %esi,%r10d
   0x0000000000001a17 <+87>:	89 d6	mov    %edx,%esi
   0x0000000000001a19 <+89>:	4d 01 d0	add    %r10,%r8
   0x0000000000001a1c <+92>:	49 c1 e9 05	shr    $0x5,%r9
   0x0000000000001a20 <+96>:	83 e6 01	and    $0x1,%esi
   0x0000000000001a23 <+99>:	4c 01 c6	add    %r8,%rsi
   0x0000000000001a26 <+102>:	4d 89 c3	mov    %r8,%r11
   0x0000000000001a29 <+105>:	41 83 e1 03	and    $0x3,%r9d

16	    if (last_bit) {
   0x0000000000001a2d <+109>:	85 c0	test   %eax,%eax
   0x0000000000001a2f <+111>:	4c 0f 45 de	cmovne %rsi,%r11
   0x0000000000001a33 <+115>:	c1 ea 1f	shr    $0x1f,%edx
   0x0000000000001a36 <+118>:	4d 89 d8	mov    %r11,%r8

17	      total += last_bit & block;
18	    }
19	    last_bit = block >> 31U;
   0x0000000000001a39 <+121>:	41 bb 40 00 00 00	mov    $0x40,%r11d

12	  for (uint64_t i = 0; i < size * 2; i += 32) {
   0x0000000000001a3f <+127>:	48 83 ff 40	cmp    $0x40,%rdi
   0x0000000000001a43 <+131>:	0f 86 ad 01 00 00	jbe    0x1bf6 <count_pairs+566>
   0x0000000000001a49 <+137>:	4d 85 c9	test   %r9,%r9
   0x0000000000001a4c <+140>:	0f 84 c9 00 00 00	je     0x1b1b <count_pairs+347>
   0x0000000000001a52 <+146>:	49 83 f9 01	cmp    $0x1,%r9
   0x0000000000001a56 <+150>:	74 7e	je     0x1ad6 <count_pairs+278>
   0x0000000000001a58 <+152>:	49 83 f9 02	cmp    $0x2,%r9
   0x0000000000001a5c <+156>:	74 3c	je     0x1a9a <count_pairs+218>

/usr/lib/gcc/x86_64-linux-gnu/11/include/avx2intrin.h:
233	  return (__m256i) ((__v32qi)__A == (__v32qi)__B);
   0x0000000000001a5e <+158>:	c4 a1 7d 74 1c 19	vpcmpeqb (%rcx,%r11,1),%ymm0,%ymm3

234	}
235	
236	extern __inline __m256i
237	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
238	_mm256_cmpeq_epi16 (__m256i __A, __m256i __B)
239	{
240	  return (__m256i) ((__v16hi)__A == (__v16hi)__B);
241	}
242	
243	extern __inline __m256i
244	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
245	_mm256_cmpeq_epi32 (__m256i __A, __m256i __B)
246	{
247	  return (__m256i) ((__v8si)__A == (__v8si)__B);
248	}
249	
250	extern __inline __m256i
251	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
252	_mm256_cmpeq_epi64 (__m256i __A, __m256i __B)
253	{
254	  return (__m256i) ((__v4di)__A == (__v4di)__B);
255	}
256	
257	extern __inline __m256i
258	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
259	_mm256_cmpgt_epi8 (__m256i __A, __m256i __B)
260	{
261	  return (__m256i) ((__v32qs)__A > (__v32qs)__B);
262	}
263	
264	extern __inline __m256i
265	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
266	_mm256_cmpgt_epi16 (__m256i __A, __m256i __B)
267	{
268	  return (__m256i) ((__v16hi)__A > (__v16hi)__B);
269	}
270	
271	extern __inline __m256i
272	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
273	_mm256_cmpgt_epi32 (__m256i __A, __m256i __B)
274	{
275	  return (__m256i) ((__v8si)__A > (__v8si)__B);
276	}
277	
278	extern __inline __m256i
279	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
280	_mm256_cmpgt_epi64 (__m256i __A, __m256i __B)
281	{
282	  return (__m256i) ((__v4di)__A > (__v4di)__B);
283	}
284	
285	extern __inline __m256i
286	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
287	_mm256_hadd_epi16 (__m256i __X, __m256i __Y)
288	{
289	  return (__m256i) __builtin_ia32_phaddw256 ((__v16hi)__X,
290						     (__v16hi)__Y);
291	}
292	
293	extern __inline __m256i
294	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
295	_mm256_hadd_epi32 (__m256i __X, __m256i __Y)
296	{
297	  return (__m256i) __builtin_ia32_phaddd256 ((__v8si)__X, (__v8si)__Y);
298	}
299	
300	extern __inline __m256i
301	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
302	_mm256_hadds_epi16 (__m256i __X, __m256i __Y)
303	{
304	  return (__m256i) __builtin_ia32_phaddsw256 ((__v16hi)__X,
305						      (__v16hi)__Y);
306	}
307	
308	extern __inline __m256i
309	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
310	_mm256_hsub_epi16 (__m256i __X, __m256i __Y)
311	{
312	  return (__m256i) __builtin_ia32_phsubw256 ((__v16hi)__X,
313						     (__v16hi)__Y);
314	}
315	
316	extern __inline __m256i
317	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
318	_mm256_hsub_epi32 (__m256i __X, __m256i __Y)
319	{
320	  return (__m256i) __builtin_ia32_phsubd256 ((__v8si)__X, (__v8si)__Y);
321	}
322	
323	extern __inline __m256i
324	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
325	_mm256_hsubs_epi16 (__m256i __X, __m256i __Y)
326	{
327	  return (__m256i) __builtin_ia32_phsubsw256 ((__v16hi)__X,
328						      (__v16hi)__Y);
329	}
330	
331	extern __inline __m256i
332	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
333	_mm256_maddubs_epi16 (__m256i __X, __m256i __Y)
334	{
335	  return (__m256i) __builtin_ia32_pmaddubsw256 ((__v32qi)__X,
336							(__v32qi)__Y);
337	}
338	
339	extern __inline __m256i
340	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
341	_mm256_madd_epi16 (__m256i __A, __m256i __B)
342	{
343	  return (__m256i)__builtin_ia32_pmaddwd256 ((__v16hi)__A,
344						     (__v16hi)__B);
345	}
346	
347	extern __inline __m256i
348	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
349	_mm256_max_epi8 (__m256i __A, __m256i __B)
350	{
351	  return (__m256i)__builtin_ia32_pmaxsb256 ((__v32qi)__A, (__v32qi)__B);
352	}
353	
354	extern __inline __m256i
355	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
356	_mm256_max_epi16 (__m256i __A, __m256i __B)
357	{
358	  return (__m256i)__builtin_ia32_pmaxsw256 ((__v16hi)__A, (__v16hi)__B);
359	}
360	
361	extern __inline __m256i
362	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
363	_mm256_max_epi32 (__m256i __A, __m256i __B)
364	{
365	  return (__m256i)__builtin_ia32_pmaxsd256 ((__v8si)__A, (__v8si)__B);
366	}
367	
368	extern __inline __m256i
369	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
370	_mm256_max_epu8 (__m256i __A, __m256i __B)
371	{
372	  return (__m256i)__builtin_ia32_pmaxub256 ((__v32qi)__A, (__v32qi)__B);
373	}
374	
375	extern __inline __m256i
376	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
377	_mm256_max_epu16 (__m256i __A, __m256i __B)
378	{
379	  return (__m256i)__builtin_ia32_pmaxuw256 ((__v16hi)__A, (__v16hi)__B);
380	}
381	
382	extern __inline __m256i
383	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
384	_mm256_max_epu32 (__m256i __A, __m256i __B)
385	{
386	  return (__m256i)__builtin_ia32_pmaxud256 ((__v8si)__A, (__v8si)__B);
387	}
388	
389	extern __inline __m256i
390	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
391	_mm256_min_epi8 (__m256i __A, __m256i __B)
392	{
393	  return (__m256i)__builtin_ia32_pminsb256 ((__v32qi)__A, (__v32qi)__B);
394	}
395	
396	extern __inline __m256i
397	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
398	_mm256_min_epi16 (__m256i __A, __m256i __B)
399	{
400	  return (__m256i)__builtin_ia32_pminsw256 ((__v16hi)__A, (__v16hi)__B);
401	}
402	
403	extern __inline __m256i
404	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
405	_mm256_min_epi32 (__m256i __A, __m256i __B)
406	{
407	  return (__m256i)__builtin_ia32_pminsd256 ((__v8si)__A, (__v8si)__B);
408	}
409	
410	extern __inline __m256i
411	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
412	_mm256_min_epu8 (__m256i __A, __m256i __B)
413	{
414	  return (__m256i)__builtin_ia32_pminub256 ((__v32qi)__A, (__v32qi)__B);
415	}
416	
417	extern __inline __m256i
418	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
419	_mm256_min_epu16 (__m256i __A, __m256i __B)
420	{
421	  return (__m256i)__builtin_ia32_pminuw256 ((__v16hi)__A, (__v16hi)__B);
422	}
423	
424	extern __inline __m256i
425	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
426	_mm256_min_epu32 (__m256i __A, __m256i __B)
427	{
428	  return (__m256i)__builtin_ia32_pminud256 ((__v8si)__A, (__v8si)__B);
429	}
430	
431	extern __inline int
432	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
433	_mm256_movemask_epi8 (__m256i __A)
434	{
435	  return __builtin_ia32_pmovmskb256 ((__v32qi)__A);
   0x0000000000001a64 <+164>:	45 31 d2	xor    %r10d,%r10d
   0x0000000000001a67 <+167>:	c5 7d d7 cb	vpmovmskb %ymm3,%r9d

ex2b.c:
15	    total += __builtin_popcount(block & (block >> 1U));
   0x0000000000001a6b <+171>:	44 89 c8	mov    %r9d,%eax
   0x0000000000001a6e <+174>:	d1 e8	shr    %eax
   0x0000000000001a70 <+176>:	44 21 c8	and    %r9d,%eax
   0x0000000000001a73 <+179>:	f3 44 0f b8 d0	popcnt %eax,%r10d
   0x0000000000001a78 <+184>:	44 89 c8	mov    %r9d,%eax
   0x0000000000001a7b <+187>:	4d 01 d0	add    %r10,%r8

16	    if (last_bit) {
   0x0000000000001a7e <+190>:	83 e0 01	and    $0x1,%eax
   0x0000000000001a81 <+193>:	4c 01 c0	add    %r8,%rax
   0x0000000000001a84 <+196>:	4c 89 c6	mov    %r8,%rsi
   0x0000000000001a87 <+199>:	85 d2	test   %edx,%edx
   0x0000000000001a89 <+201>:	48 0f 45 f0	cmovne %rax,%rsi
   0x0000000000001a8d <+205>:	44 89 ca	mov    %r9d,%edx
   0x0000000000001a90 <+208>:	49 89 f0	mov    %rsi,%r8

17	      total += last_bit & block;
18	    }
19	    last_bit = block >> 31U;
   0x0000000000001a93 <+211>:	c1 ea 1f	shr    $0x1f,%edx

12	  for (uint64_t i = 0; i < size * 2; i += 32) {
   0x0000000000001a96 <+214>:	49 83 c3 20	add    $0x20,%r11

/usr/lib/gcc/x86_64-linux-gnu/11/include/avx2intrin.h:
233	  return (__m256i) ((__v32qi)__A == (__v32qi)__B);
   0x0000000000001a9a <+218>:	c4 a1 7d 74 24 19	vpcmpeqb (%rcx,%r11,1),%ymm0,%ymm4

234	}
235	
236	extern __inline __m256i
237	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
238	_mm256_cmpeq_epi16 (__m256i __A, __m256i __B)
239	{
240	  return (__m256i) ((__v16hi)__A == (__v16hi)__B);
241	}
242	
243	extern __inline __m256i
244	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
245	_mm256_cmpeq_epi32 (__m256i __A, __m256i __B)
246	{
247	  return (__m256i) ((__v8si)__A == (__v8si)__B);
248	}
249	
250	extern __inline __m256i
251	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
252	_mm256_cmpeq_epi64 (__m256i __A, __m256i __B)
253	{
254	  return (__m256i) ((__v4di)__A == (__v4di)__B);
255	}
256	
257	extern __inline __m256i
258	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
259	_mm256_cmpgt_epi8 (__m256i __A, __m256i __B)
260	{
261	  return (__m256i) ((__v32qs)__A > (__v32qs)__B);
262	}
263	
264	extern __inline __m256i
265	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
266	_mm256_cmpgt_epi16 (__m256i __A, __m256i __B)
267	{
268	  return (__m256i) ((__v16hi)__A > (__v16hi)__B);
269	}
270	
271	extern __inline __m256i
272	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
273	_mm256_cmpgt_epi32 (__m256i __A, __m256i __B)
274	{
275	  return (__m256i) ((__v8si)__A > (__v8si)__B);
276	}
277	
278	extern __inline __m256i
279	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
280	_mm256_cmpgt_epi64 (__m256i __A, __m256i __B)
281	{
282	  return (__m256i) ((__v4di)__A > (__v4di)__B);
283	}
284	
285	extern __inline __m256i
286	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
287	_mm256_hadd_epi16 (__m256i __X, __m256i __Y)
288	{
289	  return (__m256i) __builtin_ia32_phaddw256 ((__v16hi)__X,
290						     (__v16hi)__Y);
291	}
292	
293	extern __inline __m256i
294	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
295	_mm256_hadd_epi32 (__m256i __X, __m256i __Y)
296	{
297	  return (__m256i) __builtin_ia32_phaddd256 ((__v8si)__X, (__v8si)__Y);
298	}
299	
300	extern __inline __m256i
301	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
302	_mm256_hadds_epi16 (__m256i __X, __m256i __Y)
303	{
304	  return (__m256i) __builtin_ia32_phaddsw256 ((__v16hi)__X,
305						      (__v16hi)__Y);
306	}
307	
308	extern __inline __m256i
309	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
310	_mm256_hsub_epi16 (__m256i __X, __m256i __Y)
311	{
312	  return (__m256i) __builtin_ia32_phsubw256 ((__v16hi)__X,
313						     (__v16hi)__Y);
314	}
315	
316	extern __inline __m256i
317	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
318	_mm256_hsub_epi32 (__m256i __X, __m256i __Y)
319	{
320	  return (__m256i) __builtin_ia32_phsubd256 ((__v8si)__X, (__v8si)__Y);
321	}
322	
323	extern __inline __m256i
324	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
325	_mm256_hsubs_epi16 (__m256i __X, __m256i __Y)
326	{
327	  return (__m256i) __builtin_ia32_phsubsw256 ((__v16hi)__X,
328						      (__v16hi)__Y);
329	}
330	
331	extern __inline __m256i
332	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
333	_mm256_maddubs_epi16 (__m256i __X, __m256i __Y)
334	{
335	  return (__m256i) __builtin_ia32_pmaddubsw256 ((__v32qi)__X,
336							(__v32qi)__Y);
337	}
338	
339	extern __inline __m256i
340	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
341	_mm256_madd_epi16 (__m256i __A, __m256i __B)
342	{
343	  return (__m256i)__builtin_ia32_pmaddwd256 ((__v16hi)__A,
344						     (__v16hi)__B);
345	}
346	
347	extern __inline __m256i
348	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
349	_mm256_max_epi8 (__m256i __A, __m256i __B)
350	{
351	  return (__m256i)__builtin_ia32_pmaxsb256 ((__v32qi)__A, (__v32qi)__B);
352	}
353	
354	extern __inline __m256i
355	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
356	_mm256_max_epi16 (__m256i __A, __m256i __B)
357	{
358	  return (__m256i)__builtin_ia32_pmaxsw256 ((__v16hi)__A, (__v16hi)__B);
359	}
360	
361	extern __inline __m256i
362	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
363	_mm256_max_epi32 (__m256i __A, __m256i __B)
364	{
365	  return (__m256i)__builtin_ia32_pmaxsd256 ((__v8si)__A, (__v8si)__B);
366	}
367	
368	extern __inline __m256i
369	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
370	_mm256_max_epu8 (__m256i __A, __m256i __B)
371	{
372	  return (__m256i)__builtin_ia32_pmaxub256 ((__v32qi)__A, (__v32qi)__B);
373	}
374	
375	extern __inline __m256i
376	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
377	_mm256_max_epu16 (__m256i __A, __m256i __B)
378	{
379	  return (__m256i)__builtin_ia32_pmaxuw256 ((__v16hi)__A, (__v16hi)__B);
380	}
381	
382	extern __inline __m256i
383	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
384	_mm256_max_epu32 (__m256i __A, __m256i __B)
385	{
386	  return (__m256i)__builtin_ia32_pmaxud256 ((__v8si)__A, (__v8si)__B);
387	}
388	
389	extern __inline __m256i
390	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
391	_mm256_min_epi8 (__m256i __A, __m256i __B)
392	{
393	  return (__m256i)__builtin_ia32_pminsb256 ((__v32qi)__A, (__v32qi)__B);
394	}
395	
396	extern __inline __m256i
397	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
398	_mm256_min_epi16 (__m256i __A, __m256i __B)
399	{
400	  return (__m256i)__builtin_ia32_pminsw256 ((__v16hi)__A, (__v16hi)__B);
401	}
402	
403	extern __inline __m256i
404	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
405	_mm256_min_epi32 (__m256i __A, __m256i __B)
406	{
407	  return (__m256i)__builtin_ia32_pminsd256 ((__v8si)__A, (__v8si)__B);
408	}
409	
410	extern __inline __m256i
411	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
412	_mm256_min_epu8 (__m256i __A, __m256i __B)
413	{
414	  return (__m256i)__builtin_ia32_pminub256 ((__v32qi)__A, (__v32qi)__B);
415	}
416	
417	extern __inline __m256i
418	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
419	_mm256_min_epu16 (__m256i __A, __m256i __B)
420	{
421	  return (__m256i)__builtin_ia32_pminuw256 ((__v16hi)__A, (__v16hi)__B);
422	}
423	
424	extern __inline __m256i
425	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
426	_mm256_min_epu32 (__m256i __A, __m256i __B)
427	{
428	  return (__m256i)__builtin_ia32_pminud256 ((__v8si)__A, (__v8si)__B);
429	}
430	
431	extern __inline int
432	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
433	_mm256_movemask_epi8 (__m256i __A)
434	{
435	  return __builtin_ia32_pmovmskb256 ((__v32qi)__A);
   0x0000000000001aa0 <+224>:	31 f6	xor    %esi,%esi
   0x0000000000001aa2 <+226>:	c5 7d d7 cc	vpmovmskb %ymm4,%r9d

ex2b.c:
15	    total += __builtin_popcount(block & (block >> 1U));
   0x0000000000001aa6 <+230>:	45 89 ca	mov    %r9d,%r10d
   0x0000000000001aa9 <+233>:	41 d1 ea	shr    %r10d
   0x0000000000001aac <+236>:	45 21 ca	and    %r9d,%r10d
   0x0000000000001aaf <+239>:	44 89 c8	mov    %r9d,%eax
   0x0000000000001ab2 <+242>:	f3 41 0f b8 f2	popcnt %r10d,%esi
   0x0000000000001ab7 <+247>:	83 e0 01	and    $0x1,%eax
   0x0000000000001aba <+250>:	49 01 f0	add    %rsi,%r8

16	    if (last_bit) {
   0x0000000000001abd <+253>:	4c 01 c0	add    %r8,%rax
   0x0000000000001ac0 <+256>:	4d 89 c2	mov    %r8,%r10
   0x0000000000001ac3 <+259>:	85 d2	test   %edx,%edx
   0x0000000000001ac5 <+261>:	4c 0f 45 d0	cmovne %rax,%r10
   0x0000000000001ac9 <+265>:	44 89 ca	mov    %r9d,%edx
   0x0000000000001acc <+268>:	4d 89 d0	mov    %r10,%r8

17	      total += last_bit & block;
18	    }
19	    last_bit = block >> 31U;
   0x0000000000001acf <+271>:	c1 ea 1f	shr    $0x1f,%edx

12	  for (uint64_t i = 0; i < size * 2; i += 32) {
   0x0000000000001ad2 <+274>:	49 83 c3 20	add    $0x20,%r11

/usr/lib/gcc/x86_64-linux-gnu/11/include/avx2intrin.h:
233	  return (__m256i) ((__v32qi)__A == (__v32qi)__B);
   0x0000000000001ad6 <+278>:	c4 a1 7d 74 2c 19	vpcmpeqb (%rcx,%r11,1),%ymm0,%ymm5

234	}
235	
236	extern __inline __m256i
237	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
238	_mm256_cmpeq_epi16 (__m256i __A, __m256i __B)
239	{
240	  return (__m256i) ((__v16hi)__A == (__v16hi)__B);
241	}
242	
243	extern __inline __m256i
244	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
245	_mm256_cmpeq_epi32 (__m256i __A, __m256i __B)
246	{
247	  return (__m256i) ((__v8si)__A == (__v8si)__B);
248	}
249	
250	extern __inline __m256i
251	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
252	_mm256_cmpeq_epi64 (__m256i __A, __m256i __B)
253	{
254	  return (__m256i) ((__v4di)__A == (__v4di)__B);
255	}
256	
257	extern __inline __m256i
258	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
259	_mm256_cmpgt_epi8 (__m256i __A, __m256i __B)
260	{
261	  return (__m256i) ((__v32qs)__A > (__v32qs)__B);
262	}
263	
264	extern __inline __m256i
265	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
266	_mm256_cmpgt_epi16 (__m256i __A, __m256i __B)
267	{
268	  return (__m256i) ((__v16hi)__A > (__v16hi)__B);
269	}
270	
271	extern __inline __m256i
272	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
273	_mm256_cmpgt_epi32 (__m256i __A, __m256i __B)
274	{
275	  return (__m256i) ((__v8si)__A > (__v8si)__B);
276	}
277	
278	extern __inline __m256i
279	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
280	_mm256_cmpgt_epi64 (__m256i __A, __m256i __B)
281	{
282	  return (__m256i) ((__v4di)__A > (__v4di)__B);
283	}
284	
285	extern __inline __m256i
286	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
287	_mm256_hadd_epi16 (__m256i __X, __m256i __Y)
288	{
289	  return (__m256i) __builtin_ia32_phaddw256 ((__v16hi)__X,
290						     (__v16hi)__Y);
291	}
292	
293	extern __inline __m256i
294	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
295	_mm256_hadd_epi32 (__m256i __X, __m256i __Y)
296	{
297	  return (__m256i) __builtin_ia32_phaddd256 ((__v8si)__X, (__v8si)__Y);
298	}
299	
300	extern __inline __m256i
301	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
302	_mm256_hadds_epi16 (__m256i __X, __m256i __Y)
303	{
304	  return (__m256i) __builtin_ia32_phaddsw256 ((__v16hi)__X,
305						      (__v16hi)__Y);
306	}
307	
308	extern __inline __m256i
309	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
310	_mm256_hsub_epi16 (__m256i __X, __m256i __Y)
311	{
312	  return (__m256i) __builtin_ia32_phsubw256 ((__v16hi)__X,
313						     (__v16hi)__Y);
314	}
315	
316	extern __inline __m256i
317	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
318	_mm256_hsub_epi32 (__m256i __X, __m256i __Y)
319	{
320	  return (__m256i) __builtin_ia32_phsubd256 ((__v8si)__X, (__v8si)__Y);
321	}
322	
323	extern __inline __m256i
324	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
325	_mm256_hsubs_epi16 (__m256i __X, __m256i __Y)
326	{
327	  return (__m256i) __builtin_ia32_phsubsw256 ((__v16hi)__X,
328						      (__v16hi)__Y);
329	}
330	
331	extern __inline __m256i
332	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
333	_mm256_maddubs_epi16 (__m256i __X, __m256i __Y)
334	{
335	  return (__m256i) __builtin_ia32_pmaddubsw256 ((__v32qi)__X,
336							(__v32qi)__Y);
337	}
338	
339	extern __inline __m256i
340	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
341	_mm256_madd_epi16 (__m256i __A, __m256i __B)
342	{
343	  return (__m256i)__builtin_ia32_pmaddwd256 ((__v16hi)__A,
344						     (__v16hi)__B);
345	}
346	
347	extern __inline __m256i
348	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
349	_mm256_max_epi8 (__m256i __A, __m256i __B)
350	{
351	  return (__m256i)__builtin_ia32_pmaxsb256 ((__v32qi)__A, (__v32qi)__B);
352	}
353	
354	extern __inline __m256i
355	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
356	_mm256_max_epi16 (__m256i __A, __m256i __B)
357	{
358	  return (__m256i)__builtin_ia32_pmaxsw256 ((__v16hi)__A, (__v16hi)__B);
359	}
360	
361	extern __inline __m256i
362	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
363	_mm256_max_epi32 (__m256i __A, __m256i __B)
364	{
365	  return (__m256i)__builtin_ia32_pmaxsd256 ((__v8si)__A, (__v8si)__B);
366	}
367	
368	extern __inline __m256i
369	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
370	_mm256_max_epu8 (__m256i __A, __m256i __B)
371	{
372	  return (__m256i)__builtin_ia32_pmaxub256 ((__v32qi)__A, (__v32qi)__B);
373	}
374	
375	extern __inline __m256i
376	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
377	_mm256_max_epu16 (__m256i __A, __m256i __B)
378	{
379	  return (__m256i)__builtin_ia32_pmaxuw256 ((__v16hi)__A, (__v16hi)__B);
380	}
381	
382	extern __inline __m256i
383	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
384	_mm256_max_epu32 (__m256i __A, __m256i __B)
385	{
386	  return (__m256i)__builtin_ia32_pmaxud256 ((__v8si)__A, (__v8si)__B);
387	}
388	
389	extern __inline __m256i
390	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
391	_mm256_min_epi8 (__m256i __A, __m256i __B)
392	{
393	  return (__m256i)__builtin_ia32_pminsb256 ((__v32qi)__A, (__v32qi)__B);
394	}
395	
396	extern __inline __m256i
397	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
398	_mm256_min_epi16 (__m256i __A, __m256i __B)
399	{
400	  return (__m256i)__builtin_ia32_pminsw256 ((__v16hi)__A, (__v16hi)__B);
401	}
402	
403	extern __inline __m256i
404	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
405	_mm256_min_epi32 (__m256i __A, __m256i __B)
406	{
407	  return (__m256i)__builtin_ia32_pminsd256 ((__v8si)__A, (__v8si)__B);
408	}
409	
410	extern __inline __m256i
411	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
412	_mm256_min_epu8 (__m256i __A, __m256i __B)
413	{
414	  return (__m256i)__builtin_ia32_pminub256 ((__v32qi)__A, (__v32qi)__B);
415	}
416	
417	extern __inline __m256i
418	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
419	_mm256_min_epu16 (__m256i __A, __m256i __B)
420	{
421	  return (__m256i)__builtin_ia32_pminuw256 ((__v16hi)__A, (__v16hi)__B);
422	}
423	
424	extern __inline __m256i
425	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
426	_mm256_min_epu32 (__m256i __A, __m256i __B)
427	{
428	  return (__m256i)__builtin_ia32_pminud256 ((__v8si)__A, (__v8si)__B);
429	}
430	
431	extern __inline int
432	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
433	_mm256_movemask_epi8 (__m256i __A)
434	{
435	  return __builtin_ia32_pmovmskb256 ((__v32qi)__A);
   0x0000000000001adc <+284>:	45 31 d2	xor    %r10d,%r10d
   0x0000000000001adf <+287>:	c5 7d d7 cd	vpmovmskb %ymm5,%r9d

ex2b.c:
15	    total += __builtin_popcount(block & (block >> 1U));
   0x0000000000001ae3 <+291>:	44 89 ce	mov    %r9d,%esi
   0x0000000000001ae6 <+294>:	d1 ee	shr    %esi
   0x0000000000001ae8 <+296>:	44 21 ce	and    %r9d,%esi
   0x0000000000001aeb <+299>:	44 89 c8	mov    %r9d,%eax
   0x0000000000001aee <+302>:	f3 44 0f b8 d6	popcnt %esi,%r10d
   0x0000000000001af3 <+307>:	83 e0 01	and    $0x1,%eax
   0x0000000000001af6 <+310>:	4d 01 d0	add    %r10,%r8

16	    if (last_bit) {
   0x0000000000001af9 <+313>:	4c 01 c0	add    %r8,%rax
   0x0000000000001afc <+316>:	4c 89 c6	mov    %r8,%rsi
   0x0000000000001aff <+319>:	85 d2	test   %edx,%edx
   0x0000000000001b01 <+321>:	48 0f 45 f0	cmovne %rax,%rsi
   0x0000000000001b05 <+325>:	44 89 ca	mov    %r9d,%edx
   0x0000000000001b08 <+328>:	49 83 c3 20	add    $0x20,%r11
   0x0000000000001b0c <+332>:	49 89 f0	mov    %rsi,%r8

17	      total += last_bit & block;
18	    }
19	    last_bit = block >> 31U;
   0x0000000000001b0f <+335>:	c1 ea 1f	shr    $0x1f,%edx

12	  for (uint64_t i = 0; i < size * 2; i += 32) {
   0x0000000000001b12 <+338>:	4c 39 df	cmp    %r11,%rdi
   0x0000000000001b15 <+341>:	0f 86 db 00 00 00	jbe    0x1bf6 <count_pairs+566>

/usr/lib/gcc/x86_64-linux-gnu/11/include/avx2intrin.h:
233	  return (__m256i) ((__v32qi)__A == (__v32qi)__B);
   0x0000000000001b1b <+347>:	c4 a1 7d 74 34 19	vpcmpeqb (%rcx,%r11,1),%ymm0,%ymm6

234	}
235	
236	extern __inline __m256i
237	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
238	_mm256_cmpeq_epi16 (__m256i __A, __m256i __B)
239	{
240	  return (__m256i) ((__v16hi)__A == (__v16hi)__B);
241	}
242	
243	extern __inline __m256i
244	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
245	_mm256_cmpeq_epi32 (__m256i __A, __m256i __B)
246	{
247	  return (__m256i) ((__v8si)__A == (__v8si)__B);
248	}
249	
250	extern __inline __m256i
251	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
252	_mm256_cmpeq_epi64 (__m256i __A, __m256i __B)
253	{
254	  return (__m256i) ((__v4di)__A == (__v4di)__B);
255	}
256	
257	extern __inline __m256i
258	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
259	_mm256_cmpgt_epi8 (__m256i __A, __m256i __B)
260	{
261	  return (__m256i) ((__v32qs)__A > (__v32qs)__B);
262	}
263	
264	extern __inline __m256i
265	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
266	_mm256_cmpgt_epi16 (__m256i __A, __m256i __B)
267	{
268	  return (__m256i) ((__v16hi)__A > (__v16hi)__B);
269	}
270	
271	extern __inline __m256i
272	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
273	_mm256_cmpgt_epi32 (__m256i __A, __m256i __B)
274	{
275	  return (__m256i) ((__v8si)__A > (__v8si)__B);
276	}
277	
278	extern __inline __m256i
279	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
280	_mm256_cmpgt_epi64 (__m256i __A, __m256i __B)
281	{
282	  return (__m256i) ((__v4di)__A > (__v4di)__B);
283	}
284	
285	extern __inline __m256i
286	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
287	_mm256_hadd_epi16 (__m256i __X, __m256i __Y)
288	{
289	  return (__m256i) __builtin_ia32_phaddw256 ((__v16hi)__X,
290						     (__v16hi)__Y);
291	}
292	
293	extern __inline __m256i
294	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
295	_mm256_hadd_epi32 (__m256i __X, __m256i __Y)
296	{
297	  return (__m256i) __builtin_ia32_phaddd256 ((__v8si)__X, (__v8si)__Y);
298	}
299	
300	extern __inline __m256i
301	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
302	_mm256_hadds_epi16 (__m256i __X, __m256i __Y)
303	{
304	  return (__m256i) __builtin_ia32_phaddsw256 ((__v16hi)__X,
305						      (__v16hi)__Y);
306	}
307	
308	extern __inline __m256i
309	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
310	_mm256_hsub_epi16 (__m256i __X, __m256i __Y)
311	{
312	  return (__m256i) __builtin_ia32_phsubw256 ((__v16hi)__X,
313						     (__v16hi)__Y);
314	}
315	
316	extern __inline __m256i
317	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
318	_mm256_hsub_epi32 (__m256i __X, __m256i __Y)
319	{
320	  return (__m256i) __builtin_ia32_phsubd256 ((__v8si)__X, (__v8si)__Y);
321	}
322	
323	extern __inline __m256i
324	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
325	_mm256_hsubs_epi16 (__m256i __X, __m256i __Y)
326	{
327	  return (__m256i) __builtin_ia32_phsubsw256 ((__v16hi)__X,
328						      (__v16hi)__Y);
329	}
330	
331	extern __inline __m256i
332	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
333	_mm256_maddubs_epi16 (__m256i __X, __m256i __Y)
334	{
335	  return (__m256i) __builtin_ia32_pmaddubsw256 ((__v32qi)__X,
336							(__v32qi)__Y);
337	}
338	
339	extern __inline __m256i
340	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
341	_mm256_madd_epi16 (__m256i __A, __m256i __B)
342	{
343	  return (__m256i)__builtin_ia32_pmaddwd256 ((__v16hi)__A,
344						     (__v16hi)__B);
345	}
346	
347	extern __inline __m256i
348	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
349	_mm256_max_epi8 (__m256i __A, __m256i __B)
350	{
351	  return (__m256i)__builtin_ia32_pmaxsb256 ((__v32qi)__A, (__v32qi)__B);
352	}
353	
354	extern __inline __m256i
355	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
356	_mm256_max_epi16 (__m256i __A, __m256i __B)
357	{
358	  return (__m256i)__builtin_ia32_pmaxsw256 ((__v16hi)__A, (__v16hi)__B);
359	}
360	
361	extern __inline __m256i
362	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
363	_mm256_max_epi32 (__m256i __A, __m256i __B)
364	{
365	  return (__m256i)__builtin_ia32_pmaxsd256 ((__v8si)__A, (__v8si)__B);
366	}
367	
368	extern __inline __m256i
369	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
370	_mm256_max_epu8 (__m256i __A, __m256i __B)
371	{
372	  return (__m256i)__builtin_ia32_pmaxub256 ((__v32qi)__A, (__v32qi)__B);
373	}
374	
375	extern __inline __m256i
376	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
377	_mm256_max_epu16 (__m256i __A, __m256i __B)
378	{
379	  return (__m256i)__builtin_ia32_pmaxuw256 ((__v16hi)__A, (__v16hi)__B);
380	}
381	
382	extern __inline __m256i
383	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
384	_mm256_max_epu32 (__m256i __A, __m256i __B)
385	{
386	  return (__m256i)__builtin_ia32_pmaxud256 ((__v8si)__A, (__v8si)__B);
387	}
388	
389	extern __inline __m256i
390	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
391	_mm256_min_epi8 (__m256i __A, __m256i __B)
392	{
393	  return (__m256i)__builtin_ia32_pminsb256 ((__v32qi)__A, (__v32qi)__B);
394	}
395	
396	extern __inline __m256i
397	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
398	_mm256_min_epi16 (__m256i __A, __m256i __B)
399	{
400	  return (__m256i)__builtin_ia32_pminsw256 ((__v16hi)__A, (__v16hi)__B);
401	}
402	
403	extern __inline __m256i
404	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
405	_mm256_min_epi32 (__m256i __A, __m256i __B)
406	{
407	  return (__m256i)__builtin_ia32_pminsd256 ((__v8si)__A, (__v8si)__B);
408	}
409	
410	extern __inline __m256i
411	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
412	_mm256_min_epu8 (__m256i __A, __m256i __B)
413	{
414	  return (__m256i)__builtin_ia32_pminub256 ((__v32qi)__A, (__v32qi)__B);
415	}
416	
417	extern __inline __m256i
418	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
419	_mm256_min_epu16 (__m256i __A, __m256i __B)
420	{
421	  return (__m256i)__builtin_ia32_pminuw256 ((__v16hi)__A, (__v16hi)__B);
422	}
423	
424	extern __inline __m256i
425	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
426	_mm256_min_epu32 (__m256i __A, __m256i __B)
427	{
428	  return (__m256i)__builtin_ia32_pminud256 ((__v8si)__A, (__v8si)__B);
429	}
430	
431	extern __inline int
432	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
433	_mm256_movemask_epi8 (__m256i __A)
434	{
435	  return __builtin_ia32_pmovmskb256 ((__v32qi)__A);
   0x0000000000001b21 <+353>:	c4 a1 7d 74 7c 19 20	vpcmpeqb 0x20(%rcx,%r11,1),%ymm0,%ymm7
   0x0000000000001b28 <+360>:	31 c0	xor    %eax,%eax
   0x0000000000001b2a <+362>:	c5 7d d7 d6	vpmovmskb %ymm6,%r10d

ex2b.c:
15	    total += __builtin_popcount(block & (block >> 1U));
   0x0000000000001b2e <+366>:	45 89 d1	mov    %r10d,%r9d
   0x0000000000001b31 <+369>:	41 d1 e9	shr    %r9d
   0x0000000000001b34 <+372>:	45 21 d1	and    %r10d,%r9d
   0x0000000000001b37 <+375>:	f3 41 0f b8 c1	popcnt %r9d,%eax
   0x0000000000001b3c <+380>:	4c 01 c0	add    %r8,%rax

16	    if (last_bit) {
   0x0000000000001b3f <+383>:	45 89 d0	mov    %r10d,%r8d
   0x0000000000001b42 <+386>:	4d 8d 4b 20	lea    0x20(%r11),%r9
   0x0000000000001b46 <+390>:	41 83 e0 01	and    $0x1,%r8d
   0x0000000000001b4a <+394>:	c5 7d d7 df	vpmovmskb %ymm7,%r11d
   0x0000000000001b4e <+398>:	48 89 c6	mov    %rax,%rsi
   0x0000000000001b51 <+401>:	c4 21 7d 74 44 09 20	vpcmpeqb 0x20(%rcx,%r9,1),%ymm0,%ymm8
   0x0000000000001b58 <+408>:	4c 01 c0	add    %r8,%rax
   0x0000000000001b5b <+411>:	85 d2	test   %edx,%edx
   0x0000000000001b5d <+413>:	44 89 da	mov    %r11d,%edx
   0x0000000000001b60 <+416>:	48 0f 44 c6	cmove  %rsi,%rax

15	    total += __builtin_popcount(block & (block >> 1U));
   0x0000000000001b64 <+420>:	d1 ea	shr    %edx
   0x0000000000001b66 <+422>:	44 21 da	and    %r11d,%edx
   0x0000000000001b69 <+425>:	31 f6	xor    %esi,%esi
   0x0000000000001b6b <+427>:	45 89 d8	mov    %r11d,%r8d
   0x0000000000001b6e <+430>:	f3 0f b8 f2	popcnt %edx,%esi
   0x0000000000001b72 <+434>:	41 83 e0 01	and    $0x1,%r8d
   0x0000000000001b76 <+438>:	48 01 f0	add    %rsi,%rax

16	    if (last_bit) {
   0x0000000000001b79 <+441>:	c4 c1 7d d7 f0	vpmovmskb %ymm8,%esi
   0x0000000000001b7e <+446>:	48 89 c2	mov    %rax,%rdx
   0x0000000000001b81 <+449>:	4c 01 c0	add    %r8,%rax
   0x0000000000001b84 <+452>:	45 85 d2	test   %r10d,%r10d
   0x0000000000001b87 <+455>:	41 89 f2	mov    %esi,%r10d
   0x0000000000001b8a <+458>:	48 0f 49 c2	cmovns %rdx,%rax

15	    total += __builtin_popcount(block & (block >> 1U));
   0x0000000000001b8e <+462>:	c4 21 7d 74 4c 09 40	vpcmpeqb 0x40(%rcx,%r9,1),%ymm0,%ymm9
   0x0000000000001b95 <+469>:	41 d1 ea	shr    %r10d
   0x0000000000001b98 <+472>:	41 21 f2	and    %esi,%r10d
   0x0000000000001b9b <+475>:	31 d2	xor    %edx,%edx
   0x0000000000001b9d <+477>:	f3 41 0f b8 d2	popcnt %r10d,%edx
   0x0000000000001ba2 <+482>:	41 89 f2	mov    %esi,%r10d
   0x0000000000001ba5 <+485>:	48 01 d0	add    %rdx,%rax

16	    if (last_bit) {
   0x0000000000001ba8 <+488>:	41 83 e2 01	and    $0x1,%r10d
   0x0000000000001bac <+492>:	c4 c1 7d d7 d1	vpmovmskb %ymm9,%edx
   0x0000000000001bb1 <+497>:	49 89 c0	mov    %rax,%r8
   0x0000000000001bb4 <+500>:	4c 01 d0	add    %r10,%rax
   0x0000000000001bb7 <+503>:	45 85 db	test   %r11d,%r11d
   0x0000000000001bba <+506>:	41 89 d3	mov    %edx,%r11d
   0x0000000000001bbd <+509>:	49 0f 49 c0	cmovns %r8,%rax

15	    total += __builtin_popcount(block & (block >> 1U));
   0x0000000000001bc1 <+513>:	41 d1 eb	shr    %r11d
   0x0000000000001bc4 <+516>:	41 21 d3	and    %edx,%r11d
   0x0000000000001bc7 <+519>:	45 31 c0	xor    %r8d,%r8d
   0x0000000000001bca <+522>:	f3 45 0f b8 c3	popcnt %r11d,%r8d
   0x0000000000001bcf <+527>:	49 01 c0	add    %rax,%r8

16	    if (last_bit) {
   0x0000000000001bd2 <+530>:	89 d0	mov    %edx,%eax
   0x0000000000001bd4 <+532>:	83 e0 01	and    $0x1,%eax
   0x0000000000001bd7 <+535>:	4c 01 c0	add    %r8,%rax
   0x0000000000001bda <+538>:	4d 89 c2	mov    %r8,%r10
   0x0000000000001bdd <+541>:	85 f6	test   %esi,%esi
   0x0000000000001bdf <+543>:	4c 0f 48 d0	cmovs  %rax,%r10
   0x0000000000001be3 <+547>:	4d 8d 59 60	lea    0x60(%r9),%r11
   0x0000000000001be7 <+551>:	4d 89 d0	mov    %r10,%r8

17	      total += last_bit & block;
18	    }
19	    last_bit = block >> 31U;
   0x0000000000001bea <+554>:	c1 ea 1f	shr    $0x1f,%edx

12	  for (uint64_t i = 0; i < size * 2; i += 32) {
   0x0000000000001bed <+557>:	4c 39 df	cmp    %r11,%rdi
   0x0000000000001bf0 <+560>:	0f 87 25 ff ff ff	ja     0x1b1b <count_pairs+347>
   0x0000000000001bf6 <+566>:	4c 89 c0	mov    %r8,%rax
   0x0000000000001bf9 <+569>:	c5 f8 77	vzeroupper 
   0x0000000000001bfc <+572>:	c3	retq   
   0x0000000000001bfd <+573>:	0f 1f 00	nopl   (%rax)
   0x0000000000001c00 <+576>:	45 31 c0	xor    %r8d,%r8d
   0x0000000000001c03 <+579>:	4c 89 c0	mov    %r8,%rax
   0x0000000000001c06 <+582>:	c5 f8 77	vzeroupper 
   0x0000000000001c09 <+585>:	c3	retq   
End of assembler dump.
